{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3baed4d",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95167d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b864eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench = pd.read_parquet('~/Downloads/0000.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa308547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>فلان ثم فلان يسميهم أبو رجاء فنسي عوف ثم عمر ب...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>معي صبرا قال لا تؤاخذني بما نسيت فكانت الأولى ...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>في الاثنتين ويفعل ذلك في كل ركعة حتى يفرغ من ا...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>صلى الله عليه وسلم خرج حين زاغت الشمس فصلى الظ...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>ليتني فيها جذع ليتني أكون حيا إذ يخرجك قومك فق...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>وسلم ساجد لا يرفع رأسه حتى جاءته فاطمة فطرحت ع...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>بن الخطاب عن سعيد بن يسار أنه قال كنت أسير مع ...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>سأله رجل عن اللقطة فقال اعرف وكاءها أو قال وعا...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>بن خلف وعقبة بن أبي معيط وعد السابع فلم نحفظه ...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>عائشة وعبد الله بن عباس قالا لما نزل برسول الل...</td>\n",
       "      <td>pats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 image  \\\n",
       "0    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "1    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "2    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "3    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "4    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "..                                                 ...   \n",
       "495  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "496  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "497  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "498  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "499  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
       "\n",
       "                                                answer source  \n",
       "0    فلان ثم فلان يسميهم أبو رجاء فنسي عوف ثم عمر ب...   pats  \n",
       "1    معي صبرا قال لا تؤاخذني بما نسيت فكانت الأولى ...   pats  \n",
       "2    في الاثنتين ويفعل ذلك في كل ركعة حتى يفرغ من ا...   pats  \n",
       "3    صلى الله عليه وسلم خرج حين زاغت الشمس فصلى الظ...   pats  \n",
       "4    ليتني فيها جذع ليتني أكون حيا إذ يخرجك قومك فق...   pats  \n",
       "..                                                 ...    ...  \n",
       "495  وسلم ساجد لا يرفع رأسه حتى جاءته فاطمة فطرحت ع...   pats  \n",
       "496  بن الخطاب عن سعيد بن يسار أنه قال كنت أسير مع ...   pats  \n",
       "497  سأله رجل عن اللقطة فقال اعرف وكاءها أو قال وعا...   pats  \n",
       "498  بن خلف وعقبة بن أبي معيط وعد السابع فلم نحفظه ...   pats  \n",
       "499  عائشة وعبد الله بن عباس قالا لما نزل برسول الل...   pats  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868fb84",
   "metadata": {},
   "source": [
    "# Line Segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b02156",
   "metadata": {},
   "source": [
    "## OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fecc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def segment_lines_arabic(image, min_line_height=20, gap_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Given a scanned page image (Arabic printed text),\n",
    "    returns list of bounding boxes for each text line.\n",
    "    \"\"\"\n",
    "\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image {image}\")\n",
    "\n",
    "    # Binarize image (adaptive or Otsu)\n",
    "    _, bw = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Compute horizontal projection (sum of black pixels per row)\n",
    "    proj = np.sum(bw // 255, axis=1)\n",
    "\n",
    "    # Normalize projection\n",
    "    norm = (proj - proj.min()) / (proj.max() - proj.min() + 1e-6)\n",
    "\n",
    "    # Identify row-segments where text likely exists (norm > small threshold)\n",
    "    text_rows = norm > 0.1  # tweak threshold if needed\n",
    "\n",
    "    # Find transitions between text vs non-text rows\n",
    "    lines = []\n",
    "    start = None\n",
    "    for i, val in enumerate(text_rows):\n",
    "        if val and start is None:\n",
    "            start = i\n",
    "        elif not val and start is not None:\n",
    "            end = i\n",
    "            height = end - start\n",
    "            if height >= min_line_height:\n",
    "                lines.append((start, end))\n",
    "            start = None\n",
    "    # Edge case: if line goes till image end\n",
    "    if start is not None and (len(text_rows) - start) >= min_line_height:\n",
    "        lines.append((start, len(text_rows)))\n",
    "\n",
    "    # Convert to bounding boxes: full width, with some margin\n",
    "    h, w = bw.shape\n",
    "    bboxes = [ (0, s, w, e) for (s, e) in lines ]\n",
    "\n",
    "    # Optionally cluster very close lines (gap small)\n",
    "    merged = []\n",
    "    prev = None\n",
    "    for bbox in bboxes:\n",
    "        if prev is None:\n",
    "            prev = bbox\n",
    "        else:\n",
    "            _, prev_s, _, prev_e = prev\n",
    "            _, cur_s, _, cur_e = bbox\n",
    "            gap = cur_s - prev_e\n",
    "            if gap < gap_threshold * (prev_e - prev_s):\n",
    "                # merge\n",
    "                prev = (0, prev_s, w, cur_e)\n",
    "            else:\n",
    "                merged.append(prev)\n",
    "                prev = bbox\n",
    "    if prev:\n",
    "        merged.append(prev)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../examples/ifadatul-mustafid-1-page.pdf'\n",
    "doc = convert_from_path(file_path)\n",
    "offset = 20\n",
    "\n",
    "for page_number, page_data in enumerate(doc):\n",
    "    print(\"Processing page number - \", page_number)\n",
    "\n",
    "    page_data = np.array(page_data)\n",
    "    page_height, page_width, _ = page_data.shape\n",
    "    line_boxes = segment_lines_arabic(page_data)\n",
    "\n",
    "    ot_path = f\"output/{file_path.split('/')[-1].split('.')[0] + '_lines'}\"\n",
    "    if not os.path.exists(ot_path):\n",
    "        os.makedirs(ot_path)\n",
    "\n",
    "    page_data = cv2.cvtColor(np.array(page_data), cv2.COLOR_RGB2GRAY)\n",
    "    for idx, (x0, y0, x1, y1) in enumerate(line_boxes):\n",
    "        y0_off = max(0, y0 - offset)\n",
    "        y1_off = min(page_height, y1 + offset)\n",
    "        x0_off = max(0, x0 - offset)\n",
    "        x1_off = min(page_width, x1 + offset)\n",
    "\n",
    "        line_img = page_data[y0_off:y1_off, x0_off:x1_off]\n",
    "        cv2.imwrite(f\"{ot_path}/line_{idx:03d}.png\", line_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c88fd3",
   "metadata": {},
   "source": [
    "## SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8da4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks, peak_prominences\n",
    "\n",
    "\n",
    "def directionalHistogram(img, direction='H'):\n",
    "  # a function which outputs the intensity histogram for a given image along \n",
    "  #x or y directions\n",
    "\n",
    "    (w,h) = img.shape\n",
    "    sum = []\n",
    "    pixel_count=0\n",
    "\n",
    "    if(direction=='H'):\n",
    "        for j in range(w-1):\n",
    "          for i in range(h-1):\n",
    "            pixel=img[j,i]\n",
    "            if(pixel==255):\n",
    "              pixel_count+=1\n",
    "          sum.append(pixel_count)\n",
    "          pixel_count=0\n",
    "\n",
    "    else:\n",
    "       for j in range(h-1):\n",
    "          for i in range(w-1):\n",
    "            pixel=img[i,j]\n",
    "            if(pixel==255):\n",
    "              pixel_count+=1\n",
    "          sum.append(pixel_count)\n",
    "          pixel_count=0\n",
    "\n",
    "    return sum\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def smoothHist(hist,kernel_size):\n",
    "  # A function to smooth out the noise in intensity histograms of an image\n",
    "  kernel = np.ones(kernel_size) / kernel_size\n",
    "  return np.convolve(hist, kernel, mode='same')\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def thresholding(image, threshold, typee='Binary', param1=0, param2=0):\n",
    "  # A function to apply intensity thresholding to a grey-scale image\n",
    "  # The thresholding could be simple binary thresholding or adaptive gaussian thresholding\n",
    "  # If the type is not set to 'Binary' then the parameters for adaptive thresholdinf must\n",
    "  # be used which are:\n",
    "  #param1: local region size ( preferably an odd number)\n",
    "  #param2: constant to be added to local mean\n",
    "  if(typee.lower()=='binary'):\n",
    "    ret, thresh= cv2.threshold(image,threshold,255,cv2.THRESH_BINARY_INV)\n",
    "  else:\n",
    "    thresh = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,param1,param2)\n",
    "  return thresh\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def peakinterp(interp_factor, hist, prominence_factor):\n",
    "  #Given an intensity histogram of an image, this function increases the resolution of the histogram\n",
    "  #by interpolation and then finds the sharp peaks in this histogram using find_peaks()\n",
    "  #Interp factor controls the new resolution of the histogram\n",
    "  #Prominence factor decides how much the targeted peaks stand out from the baseline of the spectrum\n",
    "  resampled_pixel_space=np.linspace(0, interp_factor*len(hist)-1,interp_factor*len(hist))*(1/interp_factor)\n",
    "  Original_pixel_space=np.linspace(0, len(hist)-1, len(hist))\n",
    "  hist_interp = np.interp(resampled_pixel_space, Original_pixel_space, hist)\n",
    "  peaks, properties = find_peaks(hist_interp, prominence=np.max(hist_interp)/prominence_factor, width=50)\n",
    "\n",
    "  return(peaks,hist_interp, resampled_pixel_space, Original_pixel_space)\n",
    "\n",
    "  ##############################################################\n",
    "\n",
    "def findGradSignChange(hist_interp, resampled_pixel_space, Original_pixel_space):\n",
    "    #Given an interpolated intensity histogram, this function finds the 1st derivative\n",
    "    # of this histogram and outputs a vector of ones and zeros determining the sign\n",
    "    # of the calculated derivative.\n",
    "    # When the sign is +ve, the vector has 1\n",
    "    # When the sign is -ve, the vector has 0\n",
    "    hist_grad=np.gradient(hist_horizontal_smooth_interp)\n",
    "    hist_grad_sign_change=np.where(hist_grad >= 0, 1, 0)\n",
    "    return hist_grad_sign_change\n",
    "\n",
    "   ##############################################################\n",
    "\n",
    "def rle(ia):\n",
    "\n",
    "        #A function which when given a sequence of binary values outputs the following:\n",
    "        # 1) the start positions of a portion of repeated values in the sequence\n",
    "        # 2) the length of the portion of repeated values\n",
    "        #This will be useful in dealing with the vector representing the sign change of\n",
    "        #1st derivative of image intensity histogram\n",
    "       \n",
    "\n",
    "        n = len(ia)\n",
    "        if n == 0: \n",
    "            return (None, None, None)\n",
    "        else:\n",
    "            y = ia[1:] != ia[:-1]               # pairwise unequal (string safe)\n",
    "            i = np.append(np.where(y), n - 1)   # must include last element posi\n",
    "            z = np.diff(np.append(-1, i))       # run lengths\n",
    "            p = np.cumsum(np.append(0, z))[:-1] # positions\n",
    "            return(z, p, ia[i])\n",
    " ##############################################################\n",
    "\n",
    "def cutPositions(runlengths, startpositions, values, threshold,interp_factor):\n",
    "  #Give a vector of ones and zeroes representing the sign change of 1st deriv. of\n",
    "  # a histogram, this function smoothes out the abrupt changes in gradient sign\n",
    "  # which might be an artifact of the gradient calculation.\n",
    "\n",
    "  # This function also gives an estimation of the possible cutting locations to\n",
    "  # extract lines\n",
    "\n",
    "  viable_index=0\n",
    "  for i in range(len(runlengths)):\n",
    "    current_length=runlengths[i]\n",
    "    if(current_length<threshold):\n",
    "      values[i]=values[viable_index]\n",
    "    viable_index=i\n",
    "\n",
    "  new_hist=[]\n",
    "  for i in range(len(startpositions)):\n",
    "    if(values[i]):\n",
    "      new_hist+=np.ones(runlengths[i]-1).tolist()\n",
    "    else:\n",
    "      new_hist+=np.zeros(runlengths[i]-1).tolist()\n",
    "\n",
    "  cutpos=[]\n",
    "  for i in range(1,len(startpositions)):\n",
    "    last=values[i-1]\n",
    "    current=values[i]\n",
    "    if((last==0 and current==1)):\n",
    "      cutpos.append(startpositions[i])\n",
    "    elif((last==1 and i==1)):\n",
    "      cutpos.append(0)\n",
    "\n",
    "\n",
    "  return (cutpos, new_hist)\n",
    "\n",
    "######################################################\n",
    "def optimalThreshold(cutpos, runlengths, startpositions, values, new_hist, peaks, init_threshold, interp_factor):\n",
    "\n",
    "  #when removing noise from the gradient sign vector prior to determining the cut locations, we use a threshold\n",
    "  #value on the run lengths of ones and zeros.\n",
    "  #An optimal value of the threshold is the value which when used gives us as many cut locations as detected peaks\n",
    "  # in the original histogram\n",
    "  while((len(cutpos)!= len(peaks))):\n",
    "      init_threshold=init_threshold+interp_factor\n",
    "      (cutpos, new_hist)=cutPositions(runlengths, startpositions, values, init_threshold,interp_factor)\n",
    "\n",
    "  (cutpos, new_hist)=cutPositions(runlengths, startpositions, values, np.abs(init_threshold-interp_factor),interp_factor)\n",
    "  cutpos=np.array(cutpos)/interp_factor\n",
    "  \n",
    "  return (cutpos, new_hist)\n",
    "\n",
    "###################################################\n",
    "\n",
    "def cropImageToLines(cutpos, image, direction='H'):\n",
    "  (w,h)=image.shape\n",
    "  cropped_images=[]\n",
    "  if(direction=='H'):\n",
    "    for i in range(len(cutpos)):\n",
    "      currentpos=cutpos[i]\n",
    "      lastpos=cutpos[i-1]\n",
    "      cropped_images.append(image[lastpos:currentpos-1,0:h-1])\n",
    "  else:\n",
    "    for i in range(len(cutpos)):\n",
    "      currentpos=cutpos[i]\n",
    "      lastpos=cutpos[i-1]\n",
    "      cropped_images.append(image[0:w-1, lastpos:currentpos-1])\n",
    "\n",
    "  return cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../examples/ifadatul-mustafid-1-page.pdf'\n",
    "doc = convert_from_path(file_path)\n",
    "offset = 20\n",
    "\n",
    "# getting the names of all the paragraph images in the directory files\n",
    "file_name = file_path.split('/')[-1].split('.')[0]\n",
    "#stripping the extension of the image file from the string of the filename for further use\n",
    "#Note that KHATT dataset provides the images with .tif extension\n",
    "# filenames_split=[filename.replace('.tif', '') for filename in filenames]\n",
    "\n",
    "for page_number, page_data in enumerate(doc):\n",
    "    print(\"Processing page number - \", page_number)\n",
    "\n",
    "    image = np.array(page_data)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    (w,h) = image.shape\n",
    "    thresh1=thresholding(image, 240, typee='Binary', param1=0, param2=0)\n",
    "\n",
    "\n",
    "    #obtaining horizontal histogram and smoothing it\n",
    "    hist_horizontal=directionalHistogram(thresh1)\n",
    "    hist_horizontal_smooth=smoothHist(hist_horizontal,17)\n",
    "\n",
    "    #Obtaining peak locations from the smoothed horizontal histogram\n",
    "    init_threshold=50\n",
    "    interp_factor=100\n",
    "    (peaks,hist_horizontal_smooth_interp,resampled_pixel_space, Original_pixel_space)=peakinterp(interp_factor, hist_horizontal_smooth, 8)\n",
    "    hist_grad_sign_change=findGradSignChange(hist_horizontal_smooth_interp, resampled_pixel_space, Original_pixel_space)\n",
    "\n",
    "    #obtaining the piecewise constant function approximating the sign change behavior of the 1st derivative of the horizontal histogram\n",
    "    runlengths, startpositions, values =rle(hist_grad_sign_change)\n",
    "    (cutpos, new_hist)=cutPositions(runlengths, startpositions, values, init_threshold, interp_factor)\n",
    "\n",
    "\n",
    "    #Removing undesired sign changes from the piecewise function which are the result of noise or numerical artifiacts, not the desired peaks\n",
    "    cutpos, new_hist=optimalThreshold(cutpos, runlengths, startpositions, values, new_hist, peaks, 50, 100)\n",
    "    #displaying lines extracted from the image\n",
    "    lines= cropImageToLines(cutpos.astype(int), thresh1)\n",
    "    \n",
    "    ot_path = f\"output/{file_path.split('/')[-1].split('.')[0] + '_lines'}\"\n",
    "    if not os.path.exists(ot_path):\n",
    "        os.makedirs(ot_path)\n",
    "\n",
    "    # cv2.imwrite(f\"{ot_path}/line_{idx:03d}.png\", line_img)\n",
    "    for i in range(len(lines)):\n",
    "        cv2.imwrite(f\"{ot_path}/line\" + str(i) + \".png\", lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6605e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dd9d80e",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6382e",
   "metadata": {},
   "source": [
    "## Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('../examples/ar_line.png')\n",
    "ar_text = pytesseract.image_to_string(img, lang=\"ara\")\n",
    "print(ar_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536fa9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a0d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import TextRecognition\n",
    "model = TextRecognition(model_name=\"arabic_PP-OCRv5_mobile_rec\")\n",
    "output = model.predict(input=\"../examples/ar_line.png\", batch_size=1)\n",
    "for res in output:\n",
    "    res.print()\n",
    "    res.save_to_img(save_path=\"./output/\")\n",
    "    res.save_to_json(save_path=\"./output/res.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac04fc",
   "metadata": {},
   "source": [
    "## PaddlePaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfbee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR  \n",
    "\n",
    "ocr = PaddleOCR(\n",
    "    text_recognition_model_name=\"arabic_PP-OCRv5_mobile_rec\",\n",
    "    use_doc_orientation_classify=False, # Use use_doc_orientation_classify to enable/disable document orientation classification model\n",
    "    use_doc_unwarping=False, # Use use_doc_unwarping to enable/disable document unwarping module\n",
    "    use_textline_orientation=True, # Use use_textline_orientation to enable/disable textline orientation classification model\n",
    "    device=\"gpu:0\", # Use device to specify GPU for model inference\n",
    ")\n",
    "# result = ocr.predict(\"https://cdn-uploads.huggingface.co/production/uploads/684ad4f6eb7d8ee8f6a92a3a/lGLRarnLFKJzE_VKOm36T.png\")  \n",
    "result = ocr.predict(\"../examples/ar_line.png\")\n",
    "for res in result:  \n",
    "    res.print()  \n",
    "    res.save_to_img(\"output\")  \n",
    "    res.save_to_json(\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc96fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "import io\n",
    "\n",
    "# Path to the input PDF file. Modify at as needed\n",
    "filePath = '../examples/idhah-qawaid-1-page.pdf'\n",
    "\n",
    "# Convert PDF to images\n",
    "doc = convert_from_path(filePath)\n",
    "\n",
    "# Extract file information\n",
    "path, fileName = os.path.split(filePath)\n",
    "fileBaseName, fileExtension = os.path.splitext(fileName)\n",
    "\n",
    "# Set Tesseract OCR command path\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
    "\n",
    "# Initialize PDF writer\n",
    "pdf_writer = PdfWriter()\n",
    "\n",
    "# List to store OCR text for each page\n",
    "ocr_text_list = []\n",
    "\n",
    "# Iterate through each page in the PDF\n",
    "for page_number, page_data in enumerate(doc):\n",
    "    print(\"Processing page number - \", page_number)\n",
    "\n",
    "    # Perform OCR for Arabic language\n",
    "    arabic_text = pytesseract.image_to_string(page_data, lang=\"ara\")\n",
    "    arabic_text = arabic_text.replace(\"\\n\", \" \")\n",
    "    ocr_text_list.append(arabic_text)\n",
    "\n",
    "    # Get a searchable PDF from the OCR result\n",
    "    pdf = pytesseract.image_to_pdf_or_hocr(page_data, extension='pdf', lang=\"ara\")\n",
    "\n",
    "    # Append the page to the output PDF\n",
    "    page = PdfReader(io.BytesIO(pdf)).pages[0]\n",
    "    pdf_writer.add_page(page)\n",
    "\n",
    "# Write the combined PDF to a file\n",
    "output_pdf_path = '{}_OCR_combined.pdf'.format(fileBaseName)\n",
    "with open(output_pdf_path, 'wb') as output_pdf:\n",
    "    pdf_writer.write(output_pdf)\n",
    "\n",
    "# Write the extracted OCR text to a text file\n",
    "output_text_path = '{}_Arabic.txt'.format(fileBaseName)\n",
    "with open(output_text_path, 'w', encoding='utf-8') as output_text_file:\n",
    "    for page_number, arabic_text in enumerate(ocr_text_list):\n",
    "        output_text_file.write(f\"Page {page_number + 1}:\\n{arabic_text}\\n\\n\")\n",
    "\n",
    "# Print output file paths\n",
    "print(f\"Combined PDF saved at: {output_pdf_path}\")\n",
    "print(f\"Translated text saved at: {output_text_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45260e73",
   "metadata": {},
   "source": [
    "## Surya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from surya.foundation import FoundationPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe599bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = '../examples/idhah-1.jpg'\n",
    "\n",
    "image = Image.open(IMAGE_PATH)\n",
    "foundation_predictor = FoundationPredictor()\n",
    "recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
    "detection_predictor = DetectionPredictor()\n",
    "\n",
    "predictions = recognition_predictor([image], det_predictor=detection_predictor)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_lines = predictions[0].text_lines\n",
    "for line in det_lines:\n",
    "    print(line.text)\n",
    "    print(line.bbox)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70db022",
   "metadata": {},
   "source": [
    "## OCRmyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03ad4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3671e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_fix_pdf(input_path: str, lang: str, dpi: str, optimize: str) -> str:\n",
    "    if shutil.which(\"ocrmypdf\") is None:\n",
    "        print(\"[ocrmypdf] not found; using original.\")\n",
    "        return input_path\n",
    "    out_dir = \"temp\"; os.makedirs(out_dir, exist_ok=True)\n",
    "    output_path = os.path.join(out_dir, \"ocr_fixed.pdf\")\n",
    "    cmd = [\n",
    "        \"ocrmypdf\", \"--language\", lang, \"--deskew\", \"--rotate-pages\", \"--force-ocr\",\n",
    "        \"--image-dpi\", dpi, \"--oversample\", dpi, \"--optimize\", optimize,\n",
    "        os.fspath(input_path), os.fspath(output_path)\n",
    "    ]\n",
    "    print(\"[ocrmypdf]\", \" \".join(cmd))\n",
    "    proc = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if proc.returncode == 0:\n",
    "        print(\"[ocrmypdf] success ->\", output_path); return output_path\n",
    "    print(\"[ocrmypdf] failed; fallback to rasterize.\\nSTDERR:\\n\", proc.stderr)\n",
    "    try:\n",
    "        image_pdf = rasterize_pdf_to_image_pdf(input_path, dpi=300)\n",
    "    except Exception as e:\n",
    "        print(\"[fallback] rasterize failed:\", e); return input_path\n",
    "    output_path2 = os.path.join(out_dir, \"ocr_fixed_from_image.pdf\")\n",
    "    cmd2 = [\n",
    "        \"ocrmypdf\", \"--language\", lang, \"--deskew\", \"--rotate-pages\",\n",
    "        \"--image-dpi\", dpi, \"--oversample\", dpi, \"--optimize\", optimize,\n",
    "        os.fspath(image_pdf), os.fspath(output_path2)\n",
    "    ]\n",
    "    print(\"[ocrmypdf fallback]\", \" \".join(cmd2))\n",
    "    proc2 = subprocess.run(cmd2, capture_output=True, text=True)\n",
    "    if proc2.returncode == 0:\n",
    "        print(\"[ocrmypdf] success via rasterize ->\", output_path2); return output_path2\n",
    "    print(\"[ocrmypdf] fallback failed; using original.\\nSTDERR:\\n\", proc2.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891e26b",
   "metadata": {},
   "source": [
    "## EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['ar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d72574",
   "metadata": {},
   "outputs": [],
   "source": [
    " # this needs to run only once to load the model into memory\n",
    "result = reader.readtext('../../misc/ifadatul-mustafid-1-page/page_1.png')\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
